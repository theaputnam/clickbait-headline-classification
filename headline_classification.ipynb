{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1247c8",
   "metadata": {},
   "source": [
    "# Headline Classification\n",
    "\n",
    "To classify headlines as clickbait and non-clickbait, we developed two supervised machine learning models:\n",
    "\n",
    "1. We simple used the most frequent words in headlines to train our model thereby trying out different number of top words.\n",
    "2. Using the insights gained from our data exploration, we developed more granular features such as different word types, word sentiment and word count in headlines.\n",
    "\n",
    "## Setup\n",
    "\n",
    "We used several libraries in this project. *csv* to load the clickbait data set, *random* to randomly select headlines for the training and test data sets, *nltk* for the natural language processing and time to measure the execution time of the models. From nltk we used *stopwords* and *word_tokenize* to tokenzie the headlines in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cbd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download(\"punkt\", quiet = True)\n",
    "nltk.download(\"stopwords\", quiet = True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99998944",
   "metadata": {},
   "source": [
    "## Natural Language Processing—Model 1\n",
    "\n",
    "In our first natural language processing model we used the top $n$ most occuring words in headlines as features.\n",
    "\n",
    "### Headline Tokenization\n",
    "\n",
    "We defined a very basic custom list of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47740b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(\n",
    "    [\n",
    "        \"a\",\n",
    "        \"am\",\n",
    "        \"an\",\n",
    "        \"and\",\n",
    "        \"are\",\n",
    "        \"as\",\n",
    "        \"at\",\n",
    "        \"be\",\n",
    "        \"because\",\n",
    "        \"been\",\n",
    "        \"but\",\n",
    "        \"by\",\n",
    "        \"did\",\n",
    "        \"do\",\n",
    "        \"for\",\n",
    "        \"from\",\n",
    "        \"get\",\n",
    "        \"has\",\n",
    "        \"have\",\n",
    "        \"if\",\n",
    "        \"in\",\n",
    "        \"into\",\n",
    "        \"is\",\n",
    "        \"it\",\n",
    "        \"its\",\n",
    "        \"just\",\n",
    "        \"of\",\n",
    "        \"on\",\n",
    "        \"or\",\n",
    "        \"out\",\n",
    "        \"over\",\n",
    "        \"than\",\n",
    "        \"that\",\n",
    "        \"the\",\n",
    "        \"their\",\n",
    "        \"then\",\n",
    "        \"there\",\n",
    "        \"to\",\n",
    "        \"was\",\n",
    "        \"where\",\n",
    "        \"which\",\n",
    "        \"will\",\n",
    "        \"with\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d196587",
   "metadata": {},
   "source": [
    "Define functions to remove stop words from a given list of words and tokenize a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b29fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_list):\n",
    "    \"\"\"Remove unecessary, meaningless stopwords from a list of words, returning a list\n",
    "    of filtered words.\n",
    "\n",
    "    Args:\n",
    "        word_list (list): List of words to filter.\n",
    "\n",
    "    Returns:\n",
    "        list\n",
    "    \"\"\"\n",
    "    filtered_word_list = list()\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word not in STOP_WORDS:\n",
    "            filtered_word_list.append(word)\n",
    "    \n",
    "    return filtered_word_list\n",
    "\n",
    "\n",
    "def tokenize_sentence(sentence):\n",
    "    \"\"\"Split sentence into tokens, remove every but alphanumeric characters, convert to\n",
    "    lower case and remove stopwords. Returning a list of cleaned tokens.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): Sentence to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        list\n",
    "    \"\"\"\n",
    "    # Tokenize headline\n",
    "    token_list = nltk.tokenize.word_tokenize(sentence, language=\"english\")\n",
    "    # Remove punctuations and special characters\n",
    "    token_list = [token for token in token_list if token.isalnum()]\n",
    "    # Convert to lowercase\n",
    "    token_list = [token.lower() for token in token_list]\n",
    "    # Remove stopwords\n",
    "    token_list = remove_stopwords(token_list)\n",
    "    \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc629cd6",
   "metadata": {},
   "source": [
    "Read clickbait data and tokenize headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5146d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['should', 'i', 'bings'], '1'], [['tv', 'female', 'friend', 'group', 'you', 'belong'], '1']]\n"
     ]
    }
   ],
   "source": [
    "CLICKBAIT_DATA_PATH = r\"data/clickbait_data.csv\"\n",
    "\n",
    "with open(CLICKBAIT_DATA_PATH, \"rt\", encoding=\"utf-8\") as clickbait_data_file:\n",
    "    # Read .csv as dictionairy with headers as keys\n",
    "    clickbait_data = csv.DictReader(clickbait_data_file)\n",
    "    token_label_list = list()\n",
    "    for row in clickbait_data:\n",
    "        # Tokenize sentence\n",
    "        token_list = tokenize_sentence(row[\"headline\"])\n",
    "        # Add token_list to token_label_list\n",
    "        token_label_list.append([token_list, row[\"clickbait\"]])\n",
    "\n",
    "print(token_label_list[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4547cf",
   "metadata": {},
   "source": [
    "### Split of Feature Set into Training and Testing\n",
    "\n",
    "Split feature set into training and testing using a 80% to 20% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f704e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of training set: 0.8\n",
      "Fraction of testing set: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Shuffle token_label_list\n",
    "random.shuffle(token_label_list)\n",
    "# Divide shuffled token_label_list into train and test set using a 80/20 ratio\n",
    "token_label_list_train, token_label_list_test = (\n",
    "    token_label_list[: int(len(token_label_list) * 0.8)],\n",
    "    token_label_list[int(len(token_label_list) * 0.8) :],\n",
    ")\n",
    "\n",
    "print(\"Fraction of training set:\", len(token_label_list_train) / len(token_label_list))\n",
    "print(\"Fraction of testing set:\", len(token_label_list_test) / len(token_label_list))\n",
    "\n",
    "# List of all tokens in training set\n",
    "token_list_train = [row[0] for row in token_label_list_train]\n",
    "# Flatten token_list_train (remove list nesting)\n",
    "token_list_train = [item for sublist in token_list_train for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffb52c",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7a0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(token_list, feature_list):\n",
    "    \"\"\"Extract features from a list of tokens given a list of features, returning a\n",
    "    dictionary of unique features for the list of tokens.\n",
    "\n",
    "    Args:\n",
    "        token_list (list): List of tokens to extract features from.\n",
    "        feature_list (list): List of features to extract from list of tokes.\n",
    "\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    # Convert list of tokens into a set to remove word duplicates\n",
    "    unique_tokens = set(token_list)\n",
    "    # Initialize an emptiy dictionary for the features\n",
    "    feature_dict = {}\n",
    "    \n",
    "    for feature in feature_list:\n",
    "        # Check if feature exists in unique_tokens\n",
    "        if feature in unique_tokens:\n",
    "            feature_dict[\"contains({})\".format(feature)] = True\n",
    "        else:\n",
    "            feature_dict[\"contains({})\".format(feature)] = False\n",
    "    \n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "def most_frequent_words(word_list, n):\n",
    "    \"\"\"Find most frequent words in a list of words, returning a list of n top words in\n",
    "    decending order.\n",
    "\n",
    "    Args:\n",
    "        word_list (list): List of words to find frequency of.\n",
    "        n (int): Number of most frequent words to return.\n",
    "\n",
    "    Returns:\n",
    "        list\n",
    "    \"\"\"\n",
    "    # Count the number of times each word occurs in word_list\n",
    "    top_words = nltk.FreqDist(word_list)\n",
    "    # Arrange words in frequency order and select top n words\n",
    "    top_words = list(top_words)[:n]\n",
    "    \n",
    "    return top_words\n",
    "\n",
    "\n",
    "def token_list_to_feature_list(token_label_list, input_feature_list):\n",
    "    \"\"\"Convert a list of lists with tokens and a corresponding label into a list of\n",
    "    lists with features and a corresponding label using an input list of features for\n",
    "    feature extraction. Returning the list of features-label lists.\n",
    "\n",
    "    Args:\n",
    "        token_label_list (list): List of lists in the form [[token_list, label], ...].\n",
    "        input_feature_list (list): List of features (e.g. most frequent words).\n",
    "\n",
    "    Returns:\n",
    "        list\n",
    "    \"\"\"\n",
    "    feature_label_list = list()\n",
    "    \n",
    "    for row in token_label_list:\n",
    "        feature_list = extract_features(row[0], input_feature_list)\n",
    "        label = row[1]\n",
    "        feature_label_list.append([feature_list, label])\n",
    "    \n",
    "    return feature_label_list\n",
    "\n",
    "\n",
    "INPUT_FEATURES = {\n",
    "    # Most frequent words in headlines\n",
    "    \"top_tokens\": most_frequent_words(token_list_train, 1000)\n",
    "}\n",
    "\n",
    "# Features for every headline\n",
    "feature_label_list_train = token_list_to_feature_list(\n",
    "    token_label_list_train, INPUT_FEATURES[\"top_tokens\"]\n",
    ")\n",
    "\n",
    "# Features for every headline\n",
    "feature_label_list_test = token_list_to_feature_list(\n",
    "    token_label_list_test, INPUT_FEATURES[\"top_tokens\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6de0a8",
   "metadata": {},
   "source": [
    "### Naïve Bayes Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67cc162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time: 21.927514000000002\n",
      "Model Accuracy: 0.95421875\n",
      "Most Informative Features\n",
      "        contains(things) = True                1 : 0      =    319.9 : 1.0\n",
      "           contains(you) = True                1 : 0      =    211.7 : 1.0\n",
      "      contains(actually) = True                1 : 0      =    182.6 : 1.0\n",
      "        contains(zodiac) = True                1 : 0      =    162.3 : 1.0\n",
      "      contains(everyone) = True                1 : 0      =    161.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "classifier = nltk.NaiveBayesClassifier.train(feature_label_list_train)\n",
    "print(\"Process time:\", time.process_time() - start_time)\n",
    "\n",
    "model_accuracy = nltk.classify.accuracy(classifier, feature_label_list_test)\n",
    "print(\"Model Accuracy:\", model_accuracy)\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec950dae",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde568db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, the deicion tree classifier takes a significant amount of time to run when n\n",
    "# is large (about 1 hour and 20 minutes for n=1000 in our test). Thus, we commented\n",
    "# these lines of code out. To run the code, simply uncomment the following lines in\n",
    "# the code block.\n",
    "\n",
    "# start_time = time.process_time()\n",
    "# classifier = nltk.DecisionTreeClassifier.train(feature_label_list_train)\n",
    "# print(\"Process time:\", time.process_time() - start_time)\n",
    "# model_accuracy = nltk.classify.accuracy(classifier, feature_label_list_test)\n",
    "# print(\"Model Accuracy:\", model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d4859",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "When testing our model the accuracy was about\n",
    "\n",
    "| n    | model         | accuracy | time (s) |\n",
    "|------|---------------|----------|----------|\n",
    "| 10   | Naive Bayes   | 0.81     | 0.3      |\n",
    "| 10   | Decision Tree | 0.81     | 5.1      |\n",
    "| 100  | Naive Bayes   | 0.90     | 2.5      |\n",
    "| 100  | Decision Tree | 0.90     | 220      |\n",
    "| 1000 | Naive Bayes   | 0.96     | 25       |\n",
    "| 1000 | Decision Tree | 0.93     | 4879     |\n",
    "\n",
    "where $n$ is the number of top most frequent words (e.g. top 10 most frequent words)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335548dd",
   "metadata": {},
   "source": [
    "## Natural Language Processing—Model 2\n",
    "\n",
    "In an alternative aproach, we used word types such as auxiliary verbs, interrogative\n",
    "pro-forms and personal pronouns as features instead of the most frequently occuring\n",
    "words. In addition, we added strongly negative and positive words from the\n",
    "[AFINN lexicon](https://github.com/fnielsen/afinn/tree/master/afinn/data) as features\n",
    "to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c81f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://en.wikipedia.org/wiki/Auxiliary_verb\n",
    "AUXILIARY_VERBS = set(\n",
    "    [\n",
    "        \"be\",\n",
    "        \"can\",\n",
    "        \"could\",\n",
    "        \"dare\",\n",
    "        \"do\",\n",
    "        \"have\",\n",
    "        \"may\",\n",
    "        \"might\",\n",
    "        \"must\",\n",
    "        \"need\",\n",
    "        \"ought\",\n",
    "        \"shall\",\n",
    "        \"should\",\n",
    "        \"will\",\n",
    "        \"would\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Source: https://en.wiktionary.org/wiki/Category:English_interrogative_pro-forms\n",
    "INTERROGATIVE_PRO_FORMS = set(\n",
    "    [\n",
    "        \"how\",\n",
    "        \"how come\",\n",
    "        \"how far\",\n",
    "        \"how long\",\n",
    "        \"how many\",\n",
    "        \"how much\",\n",
    "        \"in what world\",\n",
    "        \"since when\",\n",
    "        \"the hell\",\n",
    "        \"to what end\",\n",
    "        \"what\",\n",
    "        \"what about\",\n",
    "        \"what for\",\n",
    "        \"what kind of\",\n",
    "        \"what the heck\",\n",
    "        \"what the hell\",\n",
    "        \"whatever\",\n",
    "        \"whatsoever\",\n",
    "        \"when\",\n",
    "        \"whence\",\n",
    "        \"where\",\n",
    "        \"whereto\",\n",
    "        \"wherever\",\n",
    "        \"whether\",\n",
    "        \"which\",\n",
    "        \"which one\",\n",
    "        \"whichever\",\n",
    "        \"whichsoe'er\",\n",
    "        \"whichsoever\",\n",
    "        \"whither\",\n",
    "        \"who\",\n",
    "        \"whoever\",\n",
    "        \"whom\",\n",
    "        \"whomever\",\n",
    "        \"whomsoever\",\n",
    "        \"whose\",\n",
    "        \"whoso\",\n",
    "        \"whosoe'er\",\n",
    "        \"whosoever\",\n",
    "        \"why\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Source: https://en.wikipedia.org/wiki/English_personal_pronouns\n",
    "PERSONAL_PRONOUNS = set(\n",
    "    [\n",
    "        \"he\",\n",
    "        \"her\",\n",
    "        \"hers\",\n",
    "        \"herself\",\n",
    "        \"him\",\n",
    "        \"himselfshe\",\n",
    "        \"his\",\n",
    "        \"i\",\n",
    "        \"it\",\n",
    "        \"its\",\n",
    "        \"itself\",\n",
    "        \"me\",\n",
    "        \"mine\",\n",
    "        \"my\",\n",
    "        \"myself\",\n",
    "        \"one\",\n",
    "        \"one's\",\n",
    "        \"oneself\",\n",
    "        \"our\",\n",
    "        \"ours\",\n",
    "        \"ourself\",\n",
    "        \"ourselves\",\n",
    "        \"thee\",\n",
    "        \"their\",\n",
    "        \"theirs\",\n",
    "        \"them\",\n",
    "        \"themself\",\n",
    "        \"themselves\",\n",
    "        \"they\",\n",
    "        \"thine\",\n",
    "        \"thou\",\n",
    "        \"thy\",\n",
    "        \"thyself\",\n",
    "        \"us\",\n",
    "        \"we\",\n",
    "        \"y'all\",\n",
    "        \"y'all's\",\n",
    "        \"y'all's selves\",\n",
    "        \"y'alls\",\n",
    "        \"y'alls selves\",\n",
    "        \"ye\",\n",
    "        \"yeer\",\n",
    "        \"yeers\",\n",
    "        \"yeerselves\",\n",
    "        \"you\",\n",
    "        \"you all\",\n",
    "        \"your\",\n",
    "        \"yours\",\n",
    "        \"yourself\",\n",
    "        \"yourselves\",\n",
    "        \"youse\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622513d9",
   "metadata": {},
   "source": [
    "### Headline Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf101133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in nltk stop word list: 179\n",
      "Number of words in reduced stop word list: 138\n",
      "Number of strongly positive words in AFINN word list: 303\n",
      "Number of strongly negative words in AFINN word list: 439\n"
     ]
    }
   ],
   "source": [
    "NLTK_STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "STOP_WORDS = [\n",
    "    word\n",
    "    for word in NLTK_STOP_WORDS\n",
    "    if word not in PERSONAL_PRONOUNS\n",
    "    and word not in INTERROGATIVE_PRO_FORMS\n",
    "    and word not in AUXILIARY_VERBS\n",
    "]\n",
    "\n",
    "print(\"Number of words in nltk stop word list:\", len(NLTK_STOP_WORDS))\n",
    "print(\"Number of words in reduced stop word list:\", len(STOP_WORDS))\n",
    "\n",
    "AFINN = pd.read_csv(\"data/AFINN-en-165.txt\", sep=\"\\t\", header=None)\n",
    "\n",
    "STRONGLY_POSITIVE_WORDS = AFINN[AFINN[1] > 2]\n",
    "\n",
    "STRONGLY_NEGATIVE_WORDS = AFINN[AFINN[1] < -2]\n",
    "\n",
    "print(\n",
    "    \"Number of strongly positive words in AFINN word list:\",\n",
    "    len(STRONGLY_POSITIVE_WORDS),\n",
    ")\n",
    "print(\n",
    "    \"Number of strongly negative words in AFINN word list:\",\n",
    "    len(STRONGLY_NEGATIVE_WORDS),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69782b5",
   "metadata": {},
   "source": [
    "Read clickbait data and tokenize headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "113be792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['should', 'i', 'get', 'bings'], '1'], [['which', 'tv', 'female', 'friend', 'group', 'do', 'you', 'belong'], '1']]\n"
     ]
    }
   ],
   "source": [
    "CLICKBAIT_DATA_PATH = r\"data/clickbait_data.csv\"\n",
    "\n",
    "with open(CLICKBAIT_DATA_PATH, \"rt\", encoding=\"utf-8\") as clickbait_data_file:\n",
    "    # Fead .csv as dictionairy with headers as keys\n",
    "    clickbait_data = csv.DictReader(clickbait_data_file)\n",
    "    token_label_list = list()\n",
    "    for row in clickbait_data:\n",
    "        # Tokenize sentence\n",
    "        token_list = tokenize_sentence(row[\"headline\"])\n",
    "        # Add token_list to token_label_list\n",
    "        token_label_list.append([token_list, row[\"clickbait\"]])\n",
    "\n",
    "print(token_label_list[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bea307",
   "metadata": {},
   "source": [
    "### Split of Feature Set into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "491c17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of training set: 0.8\n",
      "Fraction of testing set: 0.2\n",
      "[[['andrew', 'marr', 'angers', 'bloggers', 'describing', 'them', 'pimpled', 'single'], '0'], [['pettitte', 'maintains', 'composure', 'victory'], '0']]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle token_label_list\n",
    "random.shuffle(token_label_list)\n",
    "# Divide shuffled token_label_list into train and test set using a 80/20 ratio\n",
    "token_label_list_train, token_label_list_test = (\n",
    "    token_label_list[: int(len(token_label_list) * 0.8)],\n",
    "    token_label_list[int(len(token_label_list) * 0.8) :],\n",
    ")\n",
    "\n",
    "print(\"Fraction of training set:\", len(token_label_list_train) / len(token_label_list))\n",
    "print(\"Fraction of testing set:\", len(token_label_list_test) / len(token_label_list))\n",
    "\n",
    "# List of all tokens in training set\n",
    "token_list_train = [row[0] for row in token_label_list_train]\n",
    "# Flatten token_list_train (remove list nesting)\n",
    "token_list_train = [item for sublist in token_list_train for item in sublist]\n",
    "\n",
    "print(token_label_list_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b124663",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10219340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'contains(auxiliary_verb)': 0, 'token_length': 8, 'contains(interrogative_pro_form)': 0, 'contains(personal_pronoun)': 1, 'contains(strongly_positive_word)': 0, 'contains(strongly_negative_word)': 0}, '0'], [{'contains(auxiliary_verb)': 0, 'token_length': 4, 'contains(interrogative_pro_form)': 0, 'contains(personal_pronoun)': 0, 'contains(strongly_positive_word)': 0, 'contains(strongly_negative_word)': 0}, '0']]\n"
     ]
    }
   ],
   "source": [
    "def extract_features_alternative(token_list, feature_set_dict):\n",
    "    \"\"\"Extract features from a list of tokens by checking membership of tokens in every\n",
    "    feature set given a dictionary of feature sets. Weight the membership of tokens in\n",
    "    feature sets based on the number of token-memberships for each token list.\n",
    "    Returning a dictionary of unique features for the list of tokens.\n",
    "\n",
    "    Args:\n",
    "        token_list (list): List of tokens to extract features from.\n",
    "        feature_set_dict (dict): Dictionary of feature sets to check membership of.\n",
    "\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    # Initialize an emptiy dictionary for the features\n",
    "    feature_dict = {}\n",
    "    for feature_set in feature_set_dict:\n",
    "        # feature_dict[\"contains({})\".format(feature_set)] = False\n",
    "        feature_dict[\"contains({})\".format(feature_set)] = 0\n",
    "        for token in token_list:\n",
    "            if token in feature_set_dict[feature_set]:\n",
    "                # feature_dict[\"contains({})\".format(feature_set)] = True\n",
    "                feature_dict[\"contains({})\".format(feature_set)] += 1\n",
    "        feature_dict[\"token_length\"] = len(token_list)\n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "def token_list_to_feature_list_alternative(token_label_list, feature_set_dict):\n",
    "    \"\"\"Convert a list of lists with tokens and a corresponding label into a list of\n",
    "    lists with features and a corresponding label using feature sets for feature\n",
    "    extraction. Returning the list of features-label lists.\n",
    "\n",
    "    Args:\n",
    "        token_label_list (list): List of lists in the form [[token_list, label], ...].\n",
    "        feature_set_dict (dict): Dictionary of feature sets to check membership of.\n",
    "\n",
    "    Returns:\n",
    "        list\n",
    "    \"\"\"\n",
    "    feature_label_list = list()\n",
    "    \n",
    "    for row in token_label_list:\n",
    "        feature_list = extract_features_alternative(row[0], feature_set_dict)\n",
    "        label = row[1]\n",
    "        feature_label_list.append([feature_list, label])\n",
    "    \n",
    "    return feature_label_list\n",
    "\n",
    "\n",
    "INPUT_FEATURE_SETS = {\n",
    "    \"auxiliary_verb\": AUXILIARY_VERBS,\n",
    "    \"interrogative_pro_form\": INTERROGATIVE_PRO_FORMS,\n",
    "    \"personal_pronoun\": PERSONAL_PRONOUNS,\n",
    "    \"strongly_positive_word\": STRONGLY_POSITIVE_WORDS,\n",
    "    \"strongly_negative_word\": STRONGLY_NEGATIVE_WORDS,\n",
    "}\n",
    "\n",
    "# Features for every headline\n",
    "feature_label_list_train = token_list_to_feature_list_alternative(\n",
    "    token_label_list_train, INPUT_FEATURE_SETS\n",
    ")\n",
    "\n",
    "# Features for every headline\n",
    "feature_label_list_test = token_list_to_feature_list_alternative(\n",
    "    token_label_list_test, INPUT_FEATURE_SETS\n",
    ")\n",
    "\n",
    "print(feature_label_list_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bcbac",
   "metadata": {},
   "source": [
    "### Naïve Bayes Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28339b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time: 0.12546499999999838\n",
      "Model Accuracy: 0.77578125\n",
      "Most Informative Features\n",
      "contains(personal_pronoun) = 3                   1 : 0      =    164.3 : 1.0\n",
      "contains(interrogative_pro_form) = 2                   1 : 0      =    103.4 : 1.0\n",
      "contains(personal_pronoun) = 2                   1 : 0      =     29.4 : 1.0\n",
      "contains(interrogative_pro_form) = 1                   1 : 0      =     23.6 : 1.0\n",
      "contains(auxiliary_verb) = 1                   1 : 0      =      6.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "classifier = nltk.NaiveBayesClassifier.train(feature_label_list_train)\n",
    "print(\"Process time:\", time.process_time() - start_time)\n",
    "\n",
    "model_accuracy = nltk.classify.accuracy(classifier, feature_label_list_test)\n",
    "print(\"Model Accuracy:\", model_accuracy)\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c07e48",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2093a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time: 1.389078000000005\n",
      "Model Accuracy: 0.77546875\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "classifier = nltk.DecisionTreeClassifier.train(feature_label_list_train)\n",
    "print(\"Process time:\", time.process_time() - start_time)\n",
    "\n",
    "model_accuracy = nltk.classify.accuracy(classifier, feature_label_list_test)\n",
    "print(\"Model Accuracy:\", model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4d490",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "When testing our model the accuracy was about\n",
    "\n",
    "| model         | accuracy | time (s) |\n",
    "|---------------|----------|----------|\n",
    "| Naive Bayes   | 0.79     | 0.16     |\n",
    "| Decision Tree | 0.79     | 1.16     |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
